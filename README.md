# CLIP-based Bolt Classification Research

Vision-Language Model (VLM) ê¸°ë°˜ ë³¼íŠ¸ ë¶„ë¥˜ ì—°êµ¬ í”„ë¡œì íŠ¸ì…ë‹ˆë‹¤. CLIP ëª¨ë¸ì„ í™œìš©í•˜ì—¬ SDNET2025 ë°ì´í„°ì…‹ì˜ ë³¼íŠ¸ ì´ë¯¸ì§€ë¥¼ ë¶„ë¥˜í•©ë‹ˆë‹¤.

## ğŸ“Š í”„ë¡œì íŠ¸ ê°œìš”

- **ëª©í‘œ**: CLIP zero-shot ë² ì´ìŠ¤ë¼ì¸(51.70%)ì—ì„œ ì‹œì‘í•˜ì—¬ domain-aware prompt engineering, ì•„í‚¤í…ì²˜ ê°œì„ , í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™”ë¥¼ í†µí•´ **69.68%** í…ŒìŠ¤íŠ¸ ì •í™•ë„ ë‹¬ì„±
- **ë°ì´í„°ì…‹**: SDNET2025 ë³¼íŠ¸ ë¶„ë¥˜
- **ë°©ë²•ë¡ **: CLIP feature extraction + Linear Probe with advanced techniques

## ğŸ“ í”„ë¡œì íŠ¸ êµ¬ì¡°

```
research_VLM/
â”œâ”€â”€ paper/                      # ë…¼ë¬¸ ê´€ë ¨ íŒŒì¼
â”‚   â”œâ”€â”€ main.tex               # LaTeX ë…¼ë¬¸ ë³¸ë¬¸
â”‚   â”œâ”€â”€ references.bib         # ì°¸ê³ ë¬¸í—Œ
â”‚   â”œâ”€â”€ figures/               # ë…¼ë¬¸ ê·¸ë¦¼ (PNG)
â”‚   â”‚   â”œâ”€â”€ confusion_matrix.png
â”‚   â”‚   â”œâ”€â”€ grid_search_heatmap.png
â”‚   â”‚   â”œâ”€â”€ performance_progression.png
â”‚   â”‚   â””â”€â”€ tsne_projection.png
â”‚   â””â”€â”€ tables/                # ë…¼ë¬¸ í…Œì´ë¸” (LaTeX)
â”‚       â”œâ”€â”€ confusion_report.txt
â”‚       â”œâ”€â”€ dataset_overview.tex
â”‚       â”œâ”€â”€ grid_search_top.tex
â”‚       â””â”€â”€ performance_progression.tex
â”‚
â”œâ”€â”€ scripts/                   # ì‹¤í—˜ ìŠ¤í¬ë¦½íŠ¸
â”‚   â”œâ”€â”€ extract_features.py           # CLIP feature ì¶”ì¶œ
â”‚   â”œâ”€â”€ train_linear_probe.py         # Linear Probe í•™ìŠµ (ìµœì¢… ë²„ì „)
â”‚   â”œâ”€â”€ zero_shot_baseline.py         # Zero-shot ë² ì´ìŠ¤ë¼ì¸
â”‚   â””â”€â”€ generate_publication_assets.py # ë…¼ë¬¸ ìë£Œ ìƒì„±
â”‚
â”œâ”€â”€ docs/                      # ë¬¸ì„œ
â”‚   â”œâ”€â”€ EXECUTION_GUIDE.md     # ì‹¤í–‰ ê°€ì´ë“œ
â”‚   â””â”€â”€ OVERLEAF_SETUP.md      # Overleaf ì„¤ì • ê°€ì´ë“œ
â”‚
â”œâ”€â”€ data/                      # ë°ì´í„° (gitignore)
â”‚   â””â”€â”€ SDNET2025/            # ë°ì´í„°ì…‹
â”‚
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```

## ğŸš€ ë¹ ë¥¸ ì‹œì‘

### 1. í™˜ê²½ ì„¤ì •

```bash
# ê°€ìƒí™˜ê²½ ìƒì„± ë° í™œì„±í™”
python -m venv venv
venv\Scripts\activate  # Windows
# source venv/bin/activate  # Linux/Mac

# í•„ìš”í•œ íŒ¨í‚¤ì§€ ì„¤ì¹˜
pip install torch torchvision
pip install open-clip-torch
pip install scikit-learn matplotlib seaborn pandas numpy
```

### 2. ë°ì´í„° ì¤€ë¹„

SDNET2025 ë°ì´í„°ì…‹ì„ `data/SDNET2025/` í´ë”ì— ë°°ì¹˜í•©ë‹ˆë‹¤.

### 3. ì‹¤í—˜ ì‹¤í–‰

#### Step 1: CLIP Feature ì¶”ì¶œ

```bash
python scripts/extract_features.py
```

- ViT-L-14 ëª¨ë¸ ì‚¬ìš©
- ì¶”ì¶œëœ featureëŠ” í”„ë¡œì íŠ¸ ë£¨íŠ¸ì— `.npy` íŒŒì¼ë¡œ ì €ì¥

#### Step 2: Zero-shot ë² ì´ìŠ¤ë¼ì¸ í‰ê°€

```bash
python scripts/zero_shot_baseline.py
```

- ì˜ˆìƒ ì„±ëŠ¥: ~51.70%

#### Step 3: Linear Probe í•™ìŠµ

```bash
python scripts/train_linear_probe.py
```

- MLP probe with mixup, class re-weighting
- ìµœì  í•˜ì´í¼íŒŒë¼ë¯¸í„° ì ìš©
- ì˜ˆìƒ ì„±ëŠ¥: ~69.68%

#### Step 4: ë…¼ë¬¸ ìë£Œ ìƒì„±

```bash
python scripts/generate_publication_assets.py
```

- `paper/figures/` ë° `paper/tables/` í´ë”ì— ìë£Œ ìƒì„±

## ğŸ“ˆ ì„±ëŠ¥ í–¥ìƒ ê³¼ì •

| ë‹¨ê³„ | ë°©ë²• | ì •í™•ë„ | í–¥ìƒ |
|------|------|--------|------|
| Baseline | CLIP Zero-shot | 51.70% | - |
| Stage 1 | Prompt Engineering + ViT-L-14 | ~60% | +8.3% |
| Stage 2 | Linear Probe + MLP | ~65% | +5% |
| Stage 3 | Mixup + Class Re-weighting | ~68% | +3% |
| Final | Hyperparameter Optimization | **69.68%** | +1.68% |

**ì´ í–¥ìƒ**: +17.98 percentage points

## ğŸ“„ ë…¼ë¬¸ ì‘ì„±

### Overleafì—ì„œ ì»´íŒŒì¼

ìì„¸í•œ ë‚´ìš©ì€ [`docs/OVERLEAF_SETUP.md`](docs/OVERLEAF_SETUP.md)ë¥¼ ì°¸ì¡°í•˜ì„¸ìš”.

**ìš”ì•½**:
1. `paper/` í´ë”ì˜ ëª¨ë“  íŒŒì¼ì„ Overleafì— ì—…ë¡œë“œ
2. Compilerë¥¼ `pdfLaTeX`ë¡œ ì„¤ì •
3. Main documentë¥¼ `main.tex`ë¡œ ì„¤ì •
4. Recompile ì‹¤í–‰

### ë¡œì»¬ì—ì„œ ì»´íŒŒì¼

```bash
cd paper
pdflatex main.tex
bibtex main
pdflatex main.tex
pdflatex main.tex
```

## ğŸ”§ ì£¼ìš” ê¸°ìˆ 

- **Model**: OpenAI CLIP (ViT-L-14)
- **Framework**: PyTorch, open-clip-torch
- **Techniques**: 
  - Domain-aware prompt engineering
  - MLP probe architecture
  - Mixup augmentation
  - Class re-weighting
  - Grid search hyperparameter optimization

## ğŸ“š ì°¸ê³  ìë£Œ

- [CLIP Paper](https://arxiv.org/abs/2103.00020)
- [OpenCLIP](https://github.com/mlfoundations/open_clip)
- ìì„¸í•œ ì‹¤í–‰ ê°€ì´ë“œ: [`docs/EXECUTION_GUIDE.md`](docs/EXECUTION_GUIDE.md)

## ğŸ¤ ê¸°ì—¬

ì´ í”„ë¡œì íŠ¸ëŠ” ì—°êµ¬ ëª©ì ìœ¼ë¡œ ê°œë°œë˜ì—ˆìŠµë‹ˆë‹¤.

## ğŸ“ ë¼ì´ì„ ìŠ¤

ì—°êµ¬ ë° êµìœ¡ ëª©ì ìœ¼ë¡œ ì‚¬ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤.

---

**ìµœì¢… ì—…ë°ì´íŠ¸**: 2025-11-18
