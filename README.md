# CLIP-based Bolt Classification Research

Vision-Language Model (VLM) ê¸°ë°˜ ë³¼íŠ¸ ë¶„ë¥˜ ì—°êµ¬ í”„ë¡œì íŠ¸ì…ë‹ˆë‹¤. CLIP ëª¨ë¸ì„ í™œìš©í•˜ì—¬ SDNET2025 ë°ì´í„°ì…‹ì˜ ë³¼íŠ¸ ì´ë¯¸ì§€ë¥¼ ë¶„ë¥˜í•©ë‹ˆë‹¤.

## ğŸ“Š í”„ë¡œì íŠ¸ ê°œìš”

### ì—°êµ¬ ëª©í‘œ
CLIP zero-shot ë² ì´ìŠ¤ë¼ì¸(51.70%)ì—ì„œ ì‹œì‘í•˜ì—¬ domain-aware prompt engineering, ì•„í‚¤í…ì²˜ ê°œì„ , í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™”ë¥¼ í†µí•´ **69.68%** í…ŒìŠ¤íŠ¸ ì •í™•ë„ ë‹¬ì„± (+17.98 percentage points)

### ë°ì´í„°ì…‹
- **SDNET2025 Bolt Classification Dataset**
  - 3ê°œ í´ë˜ìŠ¤: Loosened (324), Missing (200), Fixed (302)
  - ì´ 826ê°œ ì´ë¯¸ì§€ (640Ã—640 í•´ìƒë„)
  - í´ë˜ìŠ¤ ë¶ˆê· í˜• ë¬¸ì œ ì¡´ì¬ (1.62Ã— ë¹„ìœ¨)

### í•µì‹¬ ë°©ë²•ë¡ 
1. **CLIP Feature Extraction**: ViT-L/14 ë°±ë³¸ìœ¼ë¡œ 768ì°¨ì› feature ì¶”ì¶œ
2. **Domain-aware Prompt Engineering**: ì‚°ì—…ìš© ë³¼íŠ¸ íŠ¹í™” í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸ ì„¤ê³„
3. **MLP Probe Architecture**: 2-layer MLP with BatchNorm, Dropout
4. **Regularization Techniques**: Mixup augmentation, Class re-weighting, Label smoothing
5. **Hyperparameter Optimization**: 27ê°œ ì¡°í•© ê·¸ë¦¬ë“œ ì„œì¹˜ (LR, Weight Decay, Dropout)

### ì£¼ìš” ê¸°ì—¬
- âœ… **ì²´ê³„ì ì¸ ì ì§„ì  ê°œì„  íŒŒì´í”„ë¼ì¸**: Zero-shot â†’ Linear Probe â†’ MLP â†’ Hyperparameter Search
- âœ… **í´ë˜ìŠ¤ ë¶ˆê· í˜• ëŒ€ì‘**: Class weighting, Mixupì„ í†µí•œ ì†Œìˆ˜ í´ë˜ìŠ¤ ì„±ëŠ¥ í–¥ìƒ
- âœ… **ì¬í˜„ ê°€ëŠ¥í•œ ì‹¤í—˜ ì„¤ê³„**: ê³ ì •ëœ random seed, ëª…í™•í•œ train/test split
- âœ… **ë…¼ë¬¸ìš© ê³ í’ˆì§ˆ ì‹œê°í™”**: ìë™í™”ëœ ê·¸ë¦¼/í‘œ ìƒì„± ìŠ¤í¬ë¦½íŠ¸

## ğŸ“ í”„ë¡œì íŠ¸ êµ¬ì¡°

```
research_VLM/
â”œâ”€â”€ paper/                      # ë…¼ë¬¸ ê´€ë ¨ íŒŒì¼
â”‚   â”œâ”€â”€ figures/               # ë…¼ë¬¸ ê·¸ë¦¼ (PNG)
â”‚   â”‚   â”œâ”€â”€ confusion_matrix.png
â”‚   â”‚   â”œâ”€â”€ grid_search_heatmap.png
â”‚   â”‚   â”œâ”€â”€ performance_progression.png
â”‚   â”‚   â””â”€â”€ tsne_projection.png
â”‚   â””â”€â”€ tables/                # ë…¼ë¬¸ í…Œì´ë¸” (LaTeX)
â”‚       â”œâ”€â”€ confusion_report.txt
â”‚       â”œâ”€â”€ dataset_overview.tex
â”‚       â”œâ”€â”€ grid_search_top.tex
â”‚       â”œâ”€â”€ performance_progression.tex
â”‚       â””â”€â”€ class_performance.tex
â”‚
â”œâ”€â”€ scripts/                   # ì‹¤í—˜ ìŠ¤í¬ë¦½íŠ¸
â”‚   â”œâ”€â”€ extract_features.py           # CLIP feature ì¶”ì¶œ
â”‚   â”œâ”€â”€ train_linear_probe.py         # Linear Probe í•™ìŠµ (ìµœì¢… ë²„ì „)
â”‚   â”œâ”€â”€ zero_shot_baseline.py         # Zero-shot ë² ì´ìŠ¤ë¼ì¸
â”‚   â””â”€â”€ generate_publication_assets.py # ë…¼ë¬¸ ìë£Œ ìƒì„±
â”‚
â”œâ”€â”€ data/                      # ë°ì´í„° (gitignore)
â”‚   â””â”€â”€ SDNET2025/            # ë°ì´í„°ì…‹
â”‚
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```

## ğŸš€ ë¹ ë¥¸ ì‹œì‘

### 1. í™˜ê²½ ì„¤ì •

```bash
# ê°€ìƒí™˜ê²½ ìƒì„± ë° í™œì„±í™”
python -m venv venv
venv\Scripts\activate  # Windows
# source venv/bin/activate  # Linux/Mac

# í•„ìš”í•œ íŒ¨í‚¤ì§€ ì„¤ì¹˜
pip install torch torchvision
pip install open-clip-torch
pip install scikit-learn matplotlib seaborn pandas numpy
```

### 2. ë°ì´í„° ì¤€ë¹„

SDNET2025 ë°ì´í„°ì…‹ì„ `data/SDNET2025/` í´ë”ì— ë°°ì¹˜í•©ë‹ˆë‹¤.

### 3. ì‹¤í—˜ ì‹¤í–‰

#### Step 1: CLIP Feature ì¶”ì¶œ

```bash
python scripts/extract_features.py
```

- ViT-L-14 ëª¨ë¸ ì‚¬ìš©
- ì¶”ì¶œëœ featureëŠ” í”„ë¡œì íŠ¸ ë£¨íŠ¸ì— `.npy` íŒŒì¼ë¡œ ì €ì¥

#### Step 2: Zero-shot ë² ì´ìŠ¤ë¼ì¸ í‰ê°€

```bash
python scripts/zero_shot_baseline.py
```

- ì˜ˆìƒ ì„±ëŠ¥: ~51.70%

#### Step 3: Linear Probe í•™ìŠµ

```bash
python scripts/train_linear_probe.py
```

- MLP probe with mixup, class re-weighting
- ìµœì  í•˜ì´í¼íŒŒë¼ë¯¸í„° ì ìš©
- ì˜ˆìƒ ì„±ëŠ¥: ~69.68%

#### Step 4: ë…¼ë¬¸ ìë£Œ ìƒì„±

```bash
python scripts/generate_publication_assets.py
```

- `paper/figures/` ë° `paper/tables/` í´ë”ì— ìë£Œ ìƒì„±

## ğŸ“ˆ ì„±ëŠ¥ í–¥ìƒ ê³¼ì •

### ë‹¨ê³„ë³„ ê°œì„  ì „ëµ

| ë‹¨ê³„ | ë°©ë²• | ì •í™•ë„ | í–¥ìƒ | ì£¼ìš” ê¸°ë²• |
|------|------|--------|------|----------|
| **Baseline** | CLIP Zero-shot | 51.70% | - | ViT-B/32, ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ |
| **Stage 1** | Baseline Linear Probe | 51.70% | +0.00% | Linear classifier, 100 shots/class |
| **Stage 2** | Improved MLP Probe | 63.30% | +11.60% | MLP (256-dim), Mixup (Î±=0.3), Class weights |
| **Stage 3** | Prompt + Backbone Upgrade | 67.55% | +4.25% | Domain prompts, ViT-L/14 (768-dim) |
| **Final** | Hyperparameter Optimization | **69.68%** | +2.13% | Grid search (LR=7e-4, WD=1e-4, Dropout=0.2) |

**ì´ í–¥ìƒ**: +17.98 percentage points (34.8% relative improvement)

### í•µì‹¬ ë°œê²¬ì‚¬í•­
1. **Prompt Engineeringì˜ ì¤‘ìš”ì„±**: Domain-specific í”„ë¡¬í”„íŠ¸ê°€ +4.25% í–¥ìƒ
2. **ì•„í‚¤í…ì²˜ ê¹Šì´ì˜ íš¨ê³¼**: MLP probeê°€ Linearë³´ë‹¤ +11.6% í–¥ìƒ
3. **í•˜ì´í¼íŒŒë¼ë¯¸í„° ë¯¼ê°ë„**: ìµœì  ì¡°í•©ìœ¼ë¡œ +2.13% ì¶”ê°€ í–¥ìƒ
4. **í´ë˜ìŠ¤ ë¶ˆê· í˜• ë¬¸ì œ**: Missing í´ë˜ìŠ¤ì˜ ë‚®ì€ precision (41.79%) í™•ì¸

## ğŸ“„ ë…¼ë¬¸ ì‘ì„±

### ë…¼ë¬¸ìš© ì‹œê°í™” ìë£Œ ìƒì„±

ë…¼ë¬¸ì— ì‚¬ìš©í•  ëª¨ë“  ê·¸ë¦¼ê³¼ í‘œëŠ” ìë™ìœ¼ë¡œ ìƒì„±ë©ë‹ˆë‹¤:

```bash
python scripts/generate_publication_assets.py
```

ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” ë‹¤ìŒì„ ìƒì„±í•©ë‹ˆë‹¤:
- **ê·¸ë¦¼** (`paper/figures/`):
  - `performance_progression.png`: ë‹¨ê³„ë³„ ì„±ëŠ¥ í–¥ìƒ ê·¸ë˜í”„
  - `grid_search_heatmap.png`: í•˜ì´í¼íŒŒë¼ë¯¸í„° ê·¸ë¦¬ë“œ ì„œì¹˜ íˆíŠ¸ë§µ
  - `confusion_matrix.png`: í˜¼ë™ í–‰ë ¬ (ì›ë³¸ ë° ì •ê·œí™” ë²„ì „)
  - `tsne_projection.png`: CLIP feature ê³µê°„ì˜ t-SNE ì‹œê°í™”

- **í‘œ** (`paper/tables/`):
  - `dataset_overview.tex`: ë°ì´í„°ì…‹ í´ë˜ìŠ¤ ë¶„í¬
  - `performance_progression.tex`: ë‹¨ê³„ë³„ ì„±ëŠ¥ í–¥ìƒ
  - `grid_search_top.tex`: ê·¸ë¦¬ë“œ ì„œì¹˜ ìƒìœ„ 5ê°œ ê²°ê³¼
  - `class_performance.tex`: í´ë˜ìŠ¤ë³„ ìƒì„¸ ì„±ëŠ¥ ì§€í‘œ (Precision, Recall, F1)
  - `confusion_report.txt`: ë¶„ë¥˜ ë¦¬í¬íŠ¸ (í…ìŠ¤íŠ¸ í˜•ì‹)

**ì°¸ê³ **: ìƒì„±ëœ LaTeX í‘œ íŒŒì¼ë“¤ì€ Word ë¬¸ì„œì— ì§ì ‘ ë³µì‚¬-ë¶™ì—¬ë„£ê¸°í•˜ê±°ë‚˜, í•„ìš”ì‹œ ìˆ˜ì •í•˜ì—¬ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

## ğŸ”§ ì£¼ìš” ê¸°ìˆ  ë° ì‹¤í—˜ ì„¤ì •

### ëª¨ë¸ ë° í”„ë ˆì„ì›Œí¬
- **Backbone**: OpenAI CLIP ViT-L/14 (768-dim features)
- **Framework**: PyTorch 2.2, open-clip-torch
- **Probe Architecture**: 2-layer MLP (768 â†’ 256 â†’ 3)

### í•µì‹¬ ê¸°ë²• ìƒì„¸

#### 1. Domain-aware Prompt Engineering
```
- Loosened: "a close-up photo of a loosened steel bolt that is not properly tightened..."
- Missing: "a close-up photo showing an empty bolt hole where a steel bolt is completely missing..."
- Fixed: "a close-up photo of a properly installed and tightly secured steel bolt..."
```

#### 2. MLP Probe Architecture
- **êµ¬ì¡°**: Linear(768â†’256) â†’ BatchNorm â†’ ReLU â†’ Dropout(0.2) â†’ Linear(256â†’3)
- **ì •ê·œí™”**: BatchNorm, Dropout, Gradient clipping (max_norm=1.0)

#### 3. Regularization Techniques
- **Mixup**: Î±=0.3, í•™ìŠµ ì´ˆê¸° 70% epochì— ì ìš©
- **Class Re-weighting**: Inverse frequency weighting + Missing í´ë˜ìŠ¤ 1.5Ã— boost
- **Label Smoothing**: 0.1 smoothing factor

#### 4. ìµœì í™” ì„¤ì •
- **Optimizer**: AdamW (LR=7e-4, Weight Decay=1e-4)
- **Scheduler**: ReduceLROnPlateau (patience=25, factor=0.5)
- **Training**: 500 epochs, Batch size=32, Early stopping (patience=75)
- **Data Split**: 150 samples/class for training, ë‚˜ë¨¸ì§€ test set

## ğŸ“š ì°¸ê³  ìë£Œ

- [CLIP Paper](https://arxiv.org/abs/2103.00020)
- [OpenCLIP](https://github.com/mlfoundations/open_clip)
- [SDNET2025 Dataset](https://github.com/sdnet2025/sdnet2025)

## ğŸ¤ ê¸°ì—¬

ì´ í”„ë¡œì íŠ¸ëŠ” ì—°êµ¬ ëª©ì ìœ¼ë¡œ ê°œë°œë˜ì—ˆìŠµë‹ˆë‹¤.

## ğŸ“ ë¼ì´ì„ ìŠ¤

ì—°êµ¬ ë° êµìœ¡ ëª©ì ìœ¼ë¡œ ì‚¬ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤.

## ğŸ“‹ íŒŒì¼ ì„¤ëª…

### ìŠ¤í¬ë¦½íŠ¸ íŒŒì¼
- `extract_features.py`: CLIP ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ì—ì„œ feature ë²¡í„° ì¶”ì¶œ
- `zero_shot_baseline.py`: Zero-shot CLIP ë¶„ë¥˜ ì„±ëŠ¥ í‰ê°€
- `train_linear_probe.py`: MLP probeë¥¼ ì‚¬ìš©í•œ ë¶„ë¥˜ê¸° í•™ìŠµ ë° í‰ê°€
- `generate_publication_assets.py`: ë…¼ë¬¸ìš© ê·¸ë¦¼ê³¼ í‘œ ìë™ ìƒì„±

### ìƒì„±ë˜ëŠ” íŒŒì¼
- `clip_features.npy`: ì¶”ì¶œëœ CLIP feature ë²¡í„° (NÃ—768)
- `clip_labels.npy`: í´ë˜ìŠ¤ ë ˆì´ë¸” (0, 1, 2)
- `clip_class_names.npy`: í´ë˜ìŠ¤ ì´ë¦„ ë°°ì—´
- `clip_image_paths.npy`: ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ ë°°ì—´

**ì£¼ì˜**: `.npy` íŒŒì¼ë“¤ì€ `.gitignore`ì— í¬í•¨ë˜ì–´ ìˆì–´ Gitì— ì¶”ì ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤. í•„ìš”ì‹œ `extract_features.py`ë¥¼ ì‹¤í–‰í•˜ì—¬ ì¬ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

---

**ìµœì¢… ì—…ë°ì´íŠ¸**: 2025-01-XX
