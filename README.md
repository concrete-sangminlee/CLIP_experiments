# CLIP-based Bolt Classification Research

Vision-Language Model (VLM) ê¸°ë°˜ ë³¼íŠ¸ ê²°í•¨ ë¶„ë¥˜ ì—°êµ¬ í”„ë¡œì íŠ¸ì…ë‹ˆë‹¤. CLIP ëª¨ë¸ì„ í™œìš©í•˜ì—¬ SDNET2025 ë°ì´í„°ì…‹ì˜ ë³¼íŠ¸ ì´ë¯¸ì§€ë¥¼ ë¶„ë¥˜í•©ë‹ˆë‹¤.

## ğŸ“Š í”„ë¡œì íŠ¸ ê°œìš”

### ì—°êµ¬ ëª©í‘œ
CLIP zero-shot ë² ì´ìŠ¤ë¼ì¸(51.70%)ì—ì„œ ì‹œì‘í•˜ì—¬ domain-aware prompt engineering, ì•„í‚¤í…ì²˜ ê°œì„ , í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™”ë¥¼ í†µí•´ **69.68%** í…ŒìŠ¤íŠ¸ ì •í™•ë„ ë‹¬ì„± (+17.98 percentage points)

### ë°ì´í„°ì…‹
- **SDNET2025 Bolt Classification Dataset**
  - 3ê°œ í´ë˜ìŠ¤: Loosened (324), Missing (200), Fixed (302)
  - ì´ 826ê°œ ì´ë¯¸ì§€ (640Ã—640 í•´ìƒë„)
  - í´ë˜ìŠ¤ ë¶ˆê· í˜• ë¬¸ì œ ì¡´ì¬ (1.62Ã— ë¹„ìœ¨)

### í•µì‹¬ ë°©ë²•ë¡ 
1. **CLIP Feature Extraction**: ViT-L/14 ë°±ë³¸ìœ¼ë¡œ 768ì°¨ì› feature ì¶”ì¶œ
2. **Domain-aware Prompt Engineering**: ì‚°ì—…ìš© ë³¼íŠ¸ íŠ¹í™” í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸ ì„¤ê³„
3. **MLP Probe Architecture**: 2-layer MLP with BatchNorm, Dropout
4. **Regularization Techniques**: Mixup augmentation, Class re-weighting, Label smoothing
5. **Hyperparameter Optimization**: 27ê°œ ì¡°í•© ê·¸ë¦¬ë“œ ì„œì¹˜ (LR, Weight Decay, Dropout)

### ì£¼ìš” ê¸°ì—¬
- âœ… **ì²´ê³„ì ì¸ ì ì§„ì  ê°œì„  íŒŒì´í”„ë¼ì¸**: Zero-shot â†’ Linear Probe â†’ MLP â†’ Hyperparameter Search
- âœ… **í´ë˜ìŠ¤ ë¶ˆê· í˜• ëŒ€ì‘**: Class weighting, Mixupì„ í†µí•œ ì†Œìˆ˜ í´ë˜ìŠ¤ ì„±ëŠ¥ í–¥ìƒ
- âœ… **ì¬í˜„ ê°€ëŠ¥í•œ ì‹¤í—˜ ì„¤ê³„**: ê³ ì •ëœ random seed, ëª…í™•í•œ train/test split
- âœ… **ë…¼ë¬¸ìš© ê³ í’ˆì§ˆ ì‹œê°í™”**: ìë™í™”ëœ ê·¸ë¦¼/í‘œ ìƒì„± ìŠ¤í¬ë¦½íŠ¸

## ğŸ“ í”„ë¡œì íŠ¸ êµ¬ì¡°

```
research_VLM/
â”œâ”€â”€ paper/                      # ë…¼ë¬¸ ê´€ë ¨ íŒŒì¼
â”‚   â”œâ”€â”€ figures/               # ë…¼ë¬¸ ê·¸ë¦¼ (PNG, 300 DPI)
â”‚   â”‚   â”œâ”€â”€ confusion_matrix.png
â”‚   â”‚   â”œâ”€â”€ grid_search_heatmap.png
â”‚   â”‚   â”œâ”€â”€ performance_progression.png
â”‚   â”‚   â””â”€â”€ tsne_projection.png
â”‚   â””â”€â”€ tables/                # ë…¼ë¬¸ í…Œì´ë¸” (LaTeX í˜•ì‹)
â”‚       â”œâ”€â”€ confusion_report.txt
â”‚       â”œâ”€â”€ dataset_overview.tex
â”‚       â”œâ”€â”€ grid_search_top.tex
â”‚       â”œâ”€â”€ performance_progression.tex
â”‚       â””â”€â”€ class_performance.tex
â”‚
â”œâ”€â”€ scripts/                   # ì‹¤í—˜ ìŠ¤í¬ë¦½íŠ¸
â”‚   â”œâ”€â”€ extract_features.py           # CLIP feature ì¶”ì¶œ
â”‚   â”œâ”€â”€ train_linear_probe.py         # ì•™ìƒë¸” + pseudo label ê¸°ë°˜ MLP Probe
â”‚   â”œâ”€â”€ zero_shot_baseline.py         # Prompt ensemble zero-shot í‰ê°€
â”‚   â”œâ”€â”€ self_training_loop.py         # Iterative pseudo labeling
â”‚   â”œâ”€â”€ lora_finetune.py              # CLIP ì‹œê° ë°±ë³¸ LoRA íŒŒì¸íŠœë‹
â”‚   â”œâ”€â”€ data_augmentation.py          # í´ë˜ìŠ¤ ë¶ˆê· í˜• ëŒ€ì‘ ì¦ê°• ìƒì„±
â”‚   â”œâ”€â”€ prompt_library.py             # ë‹¤êµ­ì–´ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì •ì˜
â”‚   â””â”€â”€ generate_publication_assets.py # ë…¼ë¬¸ ìë£Œ ìë™ ìƒì„±
â”‚
â”œâ”€â”€ data/                      # ë°ì´í„°ì…‹ (Gitì— ì¶”ì ë˜ì§€ ì•ŠìŒ)
â”‚   â””â”€â”€ SDNET2025/
â”‚       â””â”€â”€ Dataset/
â”‚           â”œâ”€â”€ Defected/
â”‚           â”‚   â”œâ”€â”€ Annotated Loosen bolt & nuts/
â”‚           â”‚   â””â”€â”€ Annotated Missing bolt & nuts/
â”‚           â””â”€â”€ Fixed/
â”‚
â”œâ”€â”€ venv/                      # Python ê°€ìƒí™˜ê²½ (Gitì— ì¶”ì ë˜ì§€ ì•ŠìŒ)
â”œâ”€â”€ .gitignore                 # Git ë¬´ì‹œ íŒŒì¼ ëª©ë¡
â””â”€â”€ README.md                  # í”„ë¡œì íŠ¸ ë¬¸ì„œ
```

## ğŸš€ ë¹ ë¥¸ ì‹œì‘

### 1. í™˜ê²½ ì„¤ì •

```bash
# ê°€ìƒí™˜ê²½ ìƒì„± ë° í™œì„±í™”
python -m venv venv
venv\Scripts\activate  # Windows
# source venv/bin/activate  # Linux/Mac

# í•„ìš”í•œ íŒ¨í‚¤ì§€ ì„¤ì¹˜
pip install torch torchvision
pip install open-clip-torch
pip install scikit-learn matplotlib seaborn pandas numpy
```

### 2. ë°ì´í„° ì¤€ë¹„

SDNET2025 ë°ì´í„°ì…‹ì„ `data/SDNET2025/` í´ë”ì— ë°°ì¹˜í•©ë‹ˆë‹¤. ë°ì´í„° êµ¬ì¡°ëŠ” ë‹¤ìŒê³¼ ê°™ì•„ì•¼ í•©ë‹ˆë‹¤:

```
data/SDNET2025/
â””â”€â”€ Dataset/
    â”œâ”€â”€ Defected/
    â”‚   â”œâ”€â”€ Annotated Loosen bolt & nuts/Resized images 640-640/
    â”‚   â””â”€â”€ Annotated Missing bolt & nuts/Resized- 640-640/
    â””â”€â”€ Fixed/640-640/
```

### 3. ì‹¤í—˜ ì‹¤í–‰

#### Step 1: CLIP Feature ì¶”ì¶œ

```bash
python scripts/extract_features.py
```

**ì„¤ì •**:
- ëª¨ë¸: ViT-L-14 (OpenAI pretrained)
- ì¶œë ¥: í”„ë¡œì íŠ¸ ë£¨íŠ¸ì— `.npy` íŒŒì¼ë¡œ ì €ì¥
  - `clip_features.npy`: Feature ë²¡í„° (NÃ—768)
  - `clip_labels.npy`: í´ë˜ìŠ¤ ë ˆì´ë¸” (0, 1, 2)
  - `clip_class_names.npy`: í´ë˜ìŠ¤ ì´ë¦„ ë°°ì—´
  - `clip_image_paths.npy`: ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ ë°°ì—´

**ì°¸ê³ **: Feature íŒŒì¼ë“¤ì€ `.gitignore`ì— í¬í•¨ë˜ì–´ Gitì— ì¶”ì ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.

#### Step 2: Zero-shot ë² ì´ìŠ¤ë¼ì¸ í‰ê°€

```bash
python scripts/zero_shot_baseline.py \
  --templates base_en,materials_en,context_ko \
  --languages en,ko --max-images-per-class 120
```

**ì—…ë°ì´íŠ¸ ë‚´ìš©**:
- ë‹¤êµ­ì–´ prompt ensembleì„ êµ¬ì„±í•˜ì—¬ CLIP í…ìŠ¤íŠ¸ ì„ë² ë”©ì„ í‰ê· ë‚´ê³ , ê° ì´ë¯¸ì§€ë³„ ë¡œê·¸ë¥¼ `zero_shot_predictions.csv`ë¡œ ì €ì¥í•©ë‹ˆë‹¤.
- CSV ë¡œê·¸ëŠ” ì´í›„ pseudo labeling, self-training, probe í•™ìŠµì—ì„œ ë°”ë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

#### Step 3: MLP Probe í•™ìŠµ

```bash
python scripts/train_linear_probe.py \
  --ensemble 3 --temperature-scaling \
  --pseudo-labels-csv zero_shot_predictions.csv \
  --metadata-normalize
```

**ì£¼ìš” ê°œì„ ì **:
- Mixup, CutMix, Manifold Mixupì„ ì¡°í•©í•˜ê³  pseudo label ê°€ì¤‘ì¹˜ë¥¼ ìë™ìœ¼ë¡œ ë¶€ì—¬í•©ë‹ˆë‹¤.
- `metadata_features.npy`ê°€ ì¡´ì¬í•˜ë©´ featureì™€ concatí•˜ì—¬ ì¡°ë„Â·ê°ë„ ë©”íƒ€ ì •ë³´ë¥¼ í•¨ê»˜ í•™ìŠµí•©ë‹ˆë‹¤.
- ì„œë¡œ ë‹¤ë¥¸ seedì˜ ëª¨ë¸ì„ `--ensemble` ì˜µì…˜ìœ¼ë¡œ í•™ìŠµí•´ ë¡œì§“ì„ í‰ê· ë‚´ê³ , Temperature scaling ê²°ê³¼ê¹Œì§€ JSONìœ¼ë¡œ ê¸°ë¡í•©ë‹ˆë‹¤.
- `paper/tables/advanced_probe_summary.tex`ê°€ ìë™ ìƒì„±ë˜ì–´ ë…¼ë¬¸ ë¶€ë¡ìœ¼ë¡œ ë°”ë¡œ í™œìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

#### Step 4: ë…¼ë¬¸ ìë£Œ ìƒì„±

```bash
python scripts/generate_publication_assets.py
```

**ìƒì„±ë˜ëŠ” íŒŒì¼**:
- `paper/figures/`: ë…¼ë¬¸ìš© ê³ í•´ìƒë„ ê·¸ë¦¼ (300 DPI)
- `paper/tables/`: LaTeX í˜•ì‹ í‘œ íŒŒì¼

## ğŸ“ˆ ì„±ëŠ¥ í–¥ìƒ ê³¼ì •

### ë‹¨ê³„ë³„ ê°œì„  ì „ëµ

| ë‹¨ê³„ | ë°©ë²• | ì •í™•ë„ | í–¥ìƒ | ì£¼ìš” ê¸°ë²• |
|------|------|--------|------|----------|
| **Baseline** | CLIP Zero-shot | 51.70% | - | ViT-B/32, ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ |
| **Stage 1** | Baseline Linear Probe | 51.70% | +0.00% | Linear classifier, 100 shots/class |
| **Stage 2** | Improved MLP Probe | 63.30% | +11.60% | MLP (256-dim), Mixup (Î±=0.3), Class weights |
| **Stage 3** | Prompt + Backbone Upgrade | 67.55% | +4.25% | Domain prompts, ViT-L/14 (768-dim) |
| **Final** | Hyperparameter Optimization | **69.68%** | +2.13% | Grid search (LR=7e-4, WD=1e-4, Dropout=0.2) |

**ì´ í–¥ìƒ**: +17.98 percentage points (34.8% relative improvement)

### í•µì‹¬ ë°œê²¬ì‚¬í•­

1. **Prompt Engineeringì˜ ì¤‘ìš”ì„±**: Domain-specific í”„ë¡¬í”„íŠ¸ê°€ +4.25% í–¥ìƒ
2. **ì•„í‚¤í…ì²˜ ê¹Šì´ì˜ íš¨ê³¼**: MLP probeê°€ Linearë³´ë‹¤ +11.6% í–¥ìƒ
3. **í•˜ì´í¼íŒŒë¼ë¯¸í„° ë¯¼ê°ë„**: ìµœì  ì¡°í•©ìœ¼ë¡œ +2.13% ì¶”ê°€ í–¥ìƒ
4. **í´ë˜ìŠ¤ ë¶ˆê· í˜• ë¬¸ì œ**: Missing í´ë˜ìŠ¤ì˜ ë‚®ì€ precision (41.79%) í™•ì¸

### ğŸ”§ ì¶”ê°€ ê³ ë„í™” ëª¨ë“ˆ

- `scripts/self_training_loop.py`: labeled 60ì¥ seed â†’ pseudo label confidence ê¸°ë°˜ í™•ì¥, ë¡œê·¸(`experiments/self_training_history.csv`) ìƒì„±.
- `scripts/data_augmentation.py`: `data/SDNET2025_augmented/`ì— Cutout/ColorJitter/Blur ì¦ê°•ë³¸ì„ ìë™ ìƒì„±í•´ Missing í´ë˜ìŠ¤ ìˆ˜ë¥¼ ë³´ì •í•©ë‹ˆë‹¤.
- `scripts/lora_finetune.py`: `peft` LoRA ì–´ëŒ‘í„°ë¥¼ CLIP ì‹œê° ë°±ë³¸ì— ì£¼ì…í•´ 5 epoch ì •ë„ì˜ ê²½ëŸ‰ íŒŒì¸íŠœë‹ì„ ìˆ˜í–‰í•˜ê³  `experiments/lora_clip.pt`ë¡œ ì €ì¥í•©ë‹ˆë‹¤.
- `scripts/prompt_library.py`: ì˜ì–´/í•œêµ­ì–´ í…œí”Œë¦¿ì„ í•œ ê³³ì—ì„œ ê´€ë¦¬í•´ zero-shot, LoRA, self-training ëª¨ë‘ ë™ì¼í•œ ì¡°ê±´ ë¬˜ì‚¬ë¥¼ ê³µìœ í•©ë‹ˆë‹¤.

### ğŸ“„ ë…¼ë¬¸ ì¬í˜„ì„± ì²´í¬ë¦¬ìŠ¤íŠ¸

1. `python scripts/zero_shot_baseline.py --save-csv zero_shot_predictions.csv`
2. `python scripts/train_linear_probe.py --ensemble 3 --pseudo-labels-csv zero_shot_predictions.csv`
3. (ì˜µì…˜) `python scripts/self_training_loop.py --iterations 4 --confidence 0.9`
4. (ì˜µì…˜) `python scripts/lora_finetune.py --lora-rank 8 --epochs 5`
5. `python scripts/generate_publication_assets.py`

prompt ensemble â†’ pseudo labeling â†’ ì•™ìƒë¸” probe â†’ self-training/LoRA â†’ ë…¼ë¬¸ figure/table ìƒì„± ìˆœìœ¼ë¡œ ì‹¤í–‰í•˜ë©´ ì‹¤í—˜-ë…¼ë¬¸ ì „ì²´ íŒŒì´í”„ë¼ì¸ì„ í•œ ë²ˆì— ì¬í˜„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

## ğŸ“„ ë…¼ë¬¸ ì‘ì„±

### ë…¼ë¬¸ìš© ì‹œê°í™” ìë£Œ ìƒì„±

ë…¼ë¬¸ì— ì‚¬ìš©í•  ëª¨ë“  ê·¸ë¦¼ê³¼ í‘œëŠ” ìë™ìœ¼ë¡œ ìƒì„±ë©ë‹ˆë‹¤:

```bash
python scripts/generate_publication_assets.py
```

**ìƒì„±ë˜ëŠ” ìë£Œ**:

#### ê·¸ë¦¼ (`paper/figures/`)
- `performance_progression.png`: ë‹¨ê³„ë³„ ì„±ëŠ¥ í–¥ìƒ ê·¸ë˜í”„
- `grid_search_heatmap.png`: í•˜ì´í¼íŒŒë¼ë¯¸í„° ê·¸ë¦¬ë“œ ì„œì¹˜ íˆíŠ¸ë§µ
- `confusion_matrix.png`: í˜¼ë™ í–‰ë ¬ (ì›ë³¸ ì¹´ìš´íŠ¸ + ì •ê·œí™” í¼ì„¼íŠ¸)
- `tsne_projection.png`: CLIP feature ê³µê°„ì˜ t-SNE ì‹œê°í™”

#### í‘œ (`paper/tables/`)
- `dataset_overview.tex`: ë°ì´í„°ì…‹ í´ë˜ìŠ¤ ë¶„í¬
- `performance_progression.tex`: ë‹¨ê³„ë³„ ì„±ëŠ¥ í–¥ìƒ
- `grid_search_top.tex`: ê·¸ë¦¬ë“œ ì„œì¹˜ ìƒìœ„ 5ê°œ ê²°ê³¼
- `class_performance.tex`: í´ë˜ìŠ¤ë³„ ìƒì„¸ ì„±ëŠ¥ ì§€í‘œ (Precision, Recall, F1)
- `self_training.tex`: self-training iteration ê¸°ë¡ (ì¡´ì¬ ì‹œ ìë™ ìƒì„±)
- `confusion_report.txt`: ë¶„ë¥˜ ë¦¬í¬íŠ¸ (í…ìŠ¤íŠ¸ í˜•ì‹)

**ì°¸ê³ **: ìƒì„±ëœ LaTeX í‘œ íŒŒì¼ë“¤ì€ Word ë¬¸ì„œì— ì§ì ‘ ë³µì‚¬-ë¶™ì—¬ë„£ê¸°í•˜ê±°ë‚˜, í•„ìš”ì‹œ ìˆ˜ì •í•˜ì—¬ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

## ğŸ”§ ì£¼ìš” ê¸°ìˆ  ë° ì‹¤í—˜ ì„¤ì •

### ëª¨ë¸ ë° í”„ë ˆì„ì›Œí¬
- **Backbone**: OpenAI CLIP ViT-L/14 (768-dim features)
- **Framework**: PyTorch 2.2, open-clip-torch
- **Probe Architecture**: 2-layer MLP (768 â†’ 256 â†’ 3)

### í•µì‹¬ ê¸°ë²• ìƒì„¸

#### 1. Domain-aware Prompt Engineering

ê° í´ë˜ìŠ¤ì— ëŒ€í•œ ë„ë©”ì¸ íŠ¹í™” í”„ë¡¬í”„íŠ¸:

- **Loosened**: "a close-up photo of a loosened steel bolt that is not properly tightened and needs repair on an industrial structure"
- **Missing**: "a close-up photo showing an empty bolt hole where a steel bolt or nut is completely missing from a metal structure"
- **Fixed**: "a close-up photo of a properly installed and tightly secured steel bolt with no defects or damage on a structure"

#### 2. MLP Probe Architecture

```
Input (768-dim) 
  â†’ Linear(768â†’256) 
  â†’ BatchNorm1d 
  â†’ ReLU 
  â†’ Dropout(0.2) 
  â†’ Linear(256â†’3) 
  â†’ Output (3 classes)
```

**ì •ê·œí™” ê¸°ë²•**:
- BatchNorm: í•™ìŠµ ì•ˆì •í™”
- Dropout: ê³¼ì í•© ë°©ì§€ (rate=0.2)
- Gradient clipping: ìµœëŒ€ norm=1.0

#### 3. Regularization Techniques

- **Mixup**: Î±=0.3, í•™ìŠµ ì´ˆê¸° 70% epochì— ì ìš©
- **Class Re-weighting**: Inverse frequency weighting + Missing í´ë˜ìŠ¤ 1.5Ã— boost
- **Label Smoothing**: 0.1 smoothing factor

#### 4. ìµœì í™” ì„¤ì •

- **Optimizer**: AdamW
  - Learning Rate: 7e-4
  - Weight Decay: 1e-4
- **Scheduler**: ReduceLROnPlateau
  - Patience: 25 epochs
  - Factor: 0.5
- **Training**:
  - Epochs: 500 (ìµœëŒ€)
  - Batch size: 32
  - Early stopping: Patience=75 epochs
- **Data Split**: 150 samples/class for training, ë‚˜ë¨¸ì§€ test set
- **Random Seed**: 42 (ì¬í˜„ì„± ë³´ì¥)

## ğŸ“‹ íŒŒì¼ ì„¤ëª…

### ìŠ¤í¬ë¦½íŠ¸ íŒŒì¼

#### `extract_features.py`
CLIP ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ì—ì„œ feature ë²¡í„°ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
- ì…ë ¥: `data/SDNET2025/` í´ë”ì˜ ì´ë¯¸ì§€
- ì¶œë ¥: í”„ë¡œì íŠ¸ ë£¨íŠ¸ì— `.npy` íŒŒì¼ ì €ì¥
- ëª¨ë¸: ViT-L-14 (OpenAI pretrained)

#### `zero_shot_baseline.py`
Prompt ensemble ê¸°ë°˜ zero-shot í‰ê°€ ë° pseudo label CSV ìƒì„±ì„ ë‹´ë‹¹í•©ë‹ˆë‹¤.
- ëª¨ë¸: ê¸°ë³¸ ViT-B-32 (ì˜µì…˜ìœ¼ë¡œ ë³€ê²½ ê°€ëŠ¥)
- ì˜ì–´/í•œêµ­ì–´ í…œí”Œë¦¿ì„ ë™ì‹œì— ì‚¬ìš©í•˜ê³  temperature ìŠ¤ì¼€ì¼ë§ì„ ì ìš©í•©ë‹ˆë‹¤.
- `--save-csv` ì˜µì…˜ìœ¼ë¡œ ëª¨ë“  ì´ë¯¸ì§€ì˜ GT/ì˜ˆì¸¡/ì‹ ë¢°ë„ë¥¼ ì €ì¥í•˜ì—¬ self-training, probe í•™ìŠµì— ì¬ì‚¬ìš©í•©ë‹ˆë‹¤.

#### `train_linear_probe.py`
Pseudo label + metadata + ensembleì„ ì§€ì›í•˜ëŠ” MLP probe í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸ì…ë‹ˆë‹¤.
- Mixup/CutMix/Manifold Mixup ì¡°í•©ê³¼ class weighting, temperature scalingì„ ì§€ì›í•©ë‹ˆë‹¤.
- `experiments/<name>/metrics.json`ì— ëª¨ë“  ì„¤ì •ê³¼ ì„±ëŠ¥ì„ ì €ì¥í•˜ê³ , ë…¼ë¬¸ìš© `advanced_probe_summary.tex`ë¥¼ ìë™ ìƒì„±í•©ë‹ˆë‹¤.
- `--ensemble` ì˜µì…˜ìœ¼ë¡œ ë‹¤ì¤‘ seedë¥¼ í•™ìŠµí•´ ë¡œì§“ í‰ê· ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.

#### `self_training_loop.py`
Pseudo label confidenceë¥¼ ê¸°ë°˜ìœ¼ë¡œ labeled setì„ ë°˜ë³µì ìœ¼ë¡œ í™•ì¥í•˜ëŠ” self-training ì‹¤í—˜ ë„êµ¬ì…ë‹ˆë‹¤.
- Iterationë³„ë¡œ ì¶”ê°€ëœ ìƒ˜í”Œ ìˆ˜ì™€ ì”ì—¬ unlabeled ìˆ˜ë¥¼ CSV(`experiments/self_training_history.csv`)ë¡œ ì €ì¥í•©ë‹ˆë‹¤.
- `generate_publication_assets.py`ê°€ CSVë¥¼ ê°ì§€í•˜ë©´ ìë™ìœ¼ë¡œ LaTeX í‘œë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

#### `data_augmentation.py`
Missing í´ë˜ìŠ¤ ì¦ê°•ì„ ìœ„í•´ Cutout/ìƒ‰ê°/ë¸”ëŸ¬/ë…¸ì´ì¦ˆë¥¼ ì ìš©í•œ synthetic ì´ë¯¸ì§€ë¥¼ `data/SDNET2025_augmented/`ì— ìƒì„±í•©ë‹ˆë‹¤.

#### `lora_finetune.py`
`peft` LoRA ì–´ëŒ‘í„°ë¥¼ CLIP ë¹„ì „ ë°±ë³¸ì— ì‚½ì…í•´ ê²½ëŸ‰ íŒŒì¸íŠœë‹ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
- `experiments/lora_clip.pt`ì— visual backboneê³¼ ë¶„ë¥˜ head state dictë¥¼ ì €ì¥í•©ë‹ˆë‹¤.
- CLIP text towerëŠ” ê³ ì •í•˜ê³  ì´ë¯¸ì§€ ì¸ì½”ë”ë§Œ ì—…ë°ì´íŠ¸í•˜ì—¬ GPU ë©”ëª¨ë¦¬ë¥¼ ì ˆì•½í•©ë‹ˆë‹¤.

#### `prompt_library.py`
Zero-shot/LoRA/self-trainingì—ì„œ ì‚¬ìš©í•˜ëŠ” ì˜ì–´Â·í•œêµ­ì–´ í…œí”Œë¦¿ê³¼ í´ë˜ìŠ¤ ì„¤ëª…ì„ í•œ ê³³ì—ì„œ ê´€ë¦¬í•©ë‹ˆë‹¤.

#### `generate_publication_assets.py`
ë…¼ë¬¸ìš© ê·¸ë¦¼ê³¼ í‘œë¥¼ ìë™ìœ¼ë¡œ ìƒì„±í•©ë‹ˆë‹¤.
- ë°ì´í„°ì…‹ í†µê³„ ë¶„ì„
- ì„±ëŠ¥ ì§„í–‰ ê·¸ë˜í”„ ìƒì„±
- ê·¸ë¦¬ë“œ ì„œì¹˜ ê²°ê³¼ ì‹œê°í™”
- t-SNE feature ì‹œê°í™”
- í˜¼ë™ í–‰ë ¬ ë° ì„±ëŠ¥ ë¦¬í¬íŠ¸ ìƒì„±

### ìƒì„±ë˜ëŠ” íŒŒì¼

ë‹¤ìŒ íŒŒì¼ë“¤ì€ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ ì‹œ ìƒì„±ë˜ë©°, `.gitignore`ì— í¬í•¨ë˜ì–´ Gitì— ì¶”ì ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤:

- `clip_features.npy`: ì¶”ì¶œëœ CLIP feature ë²¡í„° (NÃ—768)
- `clip_labels.npy`: í´ë˜ìŠ¤ ë ˆì´ë¸” (0, 1, 2)
- `clip_class_names.npy`: í´ë˜ìŠ¤ ì´ë¦„ ë°°ì—´
- `clip_image_paths.npy`: ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ ë°°ì—´

**ì¬ìƒì„±**: í•„ìš”ì‹œ `extract_features.py`ë¥¼ ì‹¤í–‰í•˜ì—¬ ì¬ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

## ğŸ“š ì°¸ê³  ìë£Œ

- [CLIP Paper](https://arxiv.org/abs/2103.00020) - Radford et al., 2021
- [OpenCLIP](https://github.com/mlfoundations/open_clip) - Open-source CLIP implementation
- [SDNET2025 Dataset](https://github.com/sdnet2025/sdnet2025) - Structural defect dataset

## ğŸ¤ ê¸°ì—¬

ì´ í”„ë¡œì íŠ¸ëŠ” ì—°êµ¬ ëª©ì ìœ¼ë¡œ ê°œë°œë˜ì—ˆìŠµë‹ˆë‹¤. ì§ˆë¬¸ì´ë‚˜ ì œì•ˆì‚¬í•­ì´ ìˆìœ¼ì‹œë©´ ì´ìŠˆë¥¼ ë“±ë¡í•´ì£¼ì„¸ìš”.

## ğŸ“ ë¼ì´ì„ ìŠ¤

ì—°êµ¬ ë° êµìœ¡ ëª©ì ìœ¼ë¡œ ì‚¬ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤.

---

**ìµœì¢… ì—…ë°ì´íŠ¸**: 2025-11
